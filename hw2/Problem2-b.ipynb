{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio # load matlab file\n",
    "from scipy import signal # 2d convolve\n",
    "\n",
    "from skimage import color\n",
    "from skimage import io\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg # load img\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (i)\n",
    "### load filter (in matlab file format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filter_bank = sio.loadmat(\"./data/Problem2/filterBank.mat\")\n",
    "filter_bank[\"F\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(331, 640)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trans to grayscale\n",
    "# img = Image.open('./data/Problem2/mountain.jpg').convert('gray')\n",
    "# img.save('./output/moun_gray.jpg')\n",
    "\n",
    "img = color.rgb2gray(io.imread('./data/Problem2/zebra.jpg'));\n",
    "\n",
    "# io.imsave(fname='./output/moun_gray.jpg',arr=img)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### symmetric padding and filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211840, 38)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convolution\n",
    "# result = np.convolve(symtrc_pd_img, filter_bank[\"F\"][:,:,0], 'valid')\n",
    "# result.shape\n",
    "\n",
    "result = None # init filter result\n",
    "\n",
    "for idx in range(38):\n",
    "    tmp = signal.convolve2d(img, filter_bank[\"F\"][:,:,idx], boundary='symm', mode='same')\n",
    "    tmp = tmp.reshape(331 * 640, 1)\n",
    "    if idx==0:\n",
    "        result = tmp\n",
    "    else:\n",
    "        result = np.concatenate((result, tmp), axis=1)\n",
    "\n",
    "# result = np.array(result)\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=6, random_state=0, max_iter=1000).fit(result)\n",
    "\n",
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texture_sgmnt = kmeans.labels_.reshape(331, 640)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAABaCAYAAACPHCxJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAABUxJREFUeJzt3E+IXmcZhvHrTlKpRkORiISmkArF\njaBtQ0ECRfxTohZ1qaALN25UKoKibsS9iAtBkKRStVqktSAiRkFFXahNamtt00ophQ61RpFiI0JQ\nHxdzhC7sZKY5J+8zp9cPQmaGM+F+CXPxfeebmVQVkqTx9oweIEnaZJAlqQmDLElNGGRJasIgS1IT\nBlmSmjDIktSEQZakJgyyJDWxbycXH0zqyEJDOvjnjaMXLOcRXj16wrI2rh29YFHX/Xn0gmUd4MHR\nExZzkD2c4sKpqjp+sWt3FOQjwOkXu2oX+P2KD/dG3jV6wrI+9c3RCxb1lS+OXrCsWzg0esKiwjMH\nt3OdtywkqQmDLElNGGRJasIgS1ITBlmSmjDIktSEQZakJgyyJDVhkCWpCYMsSU0YZElqwiBLUhMG\nWZKaMMiS1IRBlqQmDLIkNWGQJakJgyxJTRhkSWrCIEtSEwZZkpowyJLUhEGWpCYMsiQ1YZAlqQmD\nLElNGGRJasIgS1ITBlmSmjDIktSEQZakJgyyJDVhkCWpCYMsSU0YZElqwiBLUhMGWZKaMMiS1IRB\nlqQmDLIkNWGQJakJgyxJTRhkSWrCIEtSEwZZkpowyJLUhEGWpCYMsiQ1YZAlqQmDLElNGGRJasIg\nS1ITBlmSmjDIktREqmr7FyfPAY8tN2e4g8BfR49YyJrPBp5vt1vz+a4ENqrq+MUu3GmQT1fV0UtZ\n1tmaz7fms4Hn2+3WfL6dnM1bFpLUhEGWpCZ2GuSvLbKijzWfb81nA8+32635fNs+247uIUuSluMt\nC0lqwiBLUhPbCnKS40keS/J4ks8sPepySnJ7knNJ/jB6yxKSXJPkZ0nOJnk4yW2jN80pyZVJfpvk\nwel8Xxi9aW5J9ib5XZIfjN4ytyRPJnkoyQNJTo/eM7ckVyW5O8mj09fgm7e8/mL3kJPsBf4IvAPY\nAO4DPlBVj8w1eqQkNwPngW9U1RtG75lbkkPAoaq6P8mrgDPA+1b0/xdgf1WdT3IF8Cvgtqr69eBp\ns0nySeAocKCqbh29Z05JngSOVtUqfygkyR3AL6vqRJKXAa+oqmdf6PrtPEK+CXi8qp6oqgvAXcB7\n55k7XlX9Avjb6B1Lqao/VdX909vPAWeBq8eumk9tOj+9e8X0ZzWvVCc5DLwbODF6i3YmyQHgZuAk\nQFVd2CrGsL0gXw089bz3N1jRF/RLSZIjwPXAb8Yumdf0lP4B4Bzwk6pa0/m+DHwa+M/oIQsp4MdJ\nziT5yOgxM3sd8Bfg69MtpxNJ9m/1CdsJcv7Px1bzCOSlIskrgXuAT1TV30fvmVNV/buq3gQcBm5K\nsopbT0luBc5V1ZnRWxZ0rKpuAN4JfHS6hbgW+4AbgK9W1fXAP4AtX4PbTpA3gGue9/5h4OkXu1CX\n33Rv9R7gzqr63ug9S5meDv4cuOgvcdkljgHvme6z3gW8Ncm3xk6aV1U9Pf19DriXzVuka7HB5i8V\n+t8ztrvZDPQL2k6Q7wOuS3LtdFP6/cD3L2mmLpvpRa+TwNmq+tLoPXNL8pokV01vvxx4O/Do2FXz\nqKrPVtXhqjrC5tfdT6vqg4NnzSbJ/umFZqan8rcAq/lup6p6BngqyeunD70N2PLF9H3b+Ef/leRj\nwClgL3B7VT18qWO7SPId4C3AwSQbwOer6uTYVbM6BnwIeGi6zwrwuar64cBNczoE3DF9N9Ae4LtV\ntbpvD1up1wL3bj5mYB/w7ar60dhJs/s4cOf0YPYJ4MNbXeyPTktSE/6kniQ1YZAlqQmDLElNGGRJ\nasIgS1ITBlmSmjDIktTEfwFgN02bK2isQwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_cmap(n, name='hsv'):\n",
    "    '''Returns a function that maps each index in 0, 1, ..., n-1 to a distinct \n",
    "    RGB color; the keyword argument name must be a standard mpl colormap name.'''\n",
    "    return plt.cm.get_cmap(name, n)\n",
    "\n",
    "def show_cmap(cmap, N):\n",
    "    fig=plt.figure()\n",
    "    ax=fig.add_subplot(111)   \n",
    "    plt.axis('scaled')\n",
    "    ax.set_xlim([ 0, N])\n",
    "    ax.set_ylim([-0.5, 0.5])\n",
    "    for i in range(N):\n",
    "        rect = plt.Rectangle((i, -0.5), 1, 1, facecolor=cmap(i))\n",
    "        ax.add_artist(rect)\n",
    "    ax.set_yticks([])\n",
    "    plt.show()\n",
    "\n",
    "cmap = get_cmap(6)\n",
    "show_cmap(cmap, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imsave(\"./output/zebra_texture_segmentation.jpg\", texture_sgmnt, cmap=cmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (ii) \n",
    "\n",
    "### RGB to Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211840, 3)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab = color.rgb2lab(io.imread('./data/Problem2/zebra.jpg'))\n",
    "lab = lab.reshape(-1, 3)\n",
    "lab.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# concatenate lab and filter result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211840, 41)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = np.concatenate((result, lab), axis=1)\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1], dtype=int32)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=6, random_state=0, max_iter=1000).fit(result)\n",
    "\n",
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(331, 640)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texture_sgmnt = kmeans.labels_.reshape(331, 640)\n",
    "texture_sgmnt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imsave(\"./output/zebra_texture_segmentation_withLab.jpg\", texture_sgmnt, cmap=cmap)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
